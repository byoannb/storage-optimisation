---
title: "**Algorithme d'optimisation de stockage**"
author: "Yoann Bonnet, Victorien Leconte, Hugo Picard"
date: "M2 Data Science, 2023 - 2024"
geometry: "left=1.5cm,right=1.5cm,top=1.5cm,bottom=2cm"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,message=FALSE,warning=FALSE)
rm(list=ls())
graphics.off()
```

```{r echo=FALSE}
library(Rcpp)
library(ggplot2)
library(gridExtra)
library(microbenchmark)
```

# Algorithme _First-fit-decreasing bin packing_

L'algorithme **First-Fit Decreasing Bin Packing (FFD)** est une méthode d'optimisation utilisée en informatique et en recherche opérationnelle pour résoudre le problème de **bin packing**. Ce problème classique consiste à répartir un ensemble d'objets de tailles différentes, ici, il s'agit de jeux, dans le plus petit nombre possible de bacs de capacité fixe, ici espaces mémoires.

## Implémentations en `R` et en `C++`

```{r}
ffd_bin_packing <- function(games, storage) {
  sorted_games <- sort(games, decreasing = TRUE)
  bins <- list()

  for (game in sorted_games) {
    fitted <- FALSE
    for (i in seq_along(bins)) {
      if (sum(bins[[i]]) + game <= storage) {
        bins[[i]] <- c(bins[[i]], game)
        fitted <- TRUE
        break
      }
    }

        if (!fitted) {
      bins <- c(bins, list(game))
    }
  }

  return(bins)
}
```

```{Rcpp}
#include <Rcpp.h> 
using namespace Rcpp; 
using namespace std;

#include<vector> 
#include <iostream>
#include <algorithm>
#include <numeric>

// [[Rcpp::export]] 
std::vector<std::vector<int>> ffd_bin_packing_Rcpp(std::vector<int>& games, int storage)
  {
    sort(games.begin(), games.end(), greater<int>());

    vector<vector<int>> bins;

    for (int game : games) {
        bool fitted = false;
        for (vector<int>& bin : bins) {
            if (accumulate(bin.begin(), bin.end(), 0) + game <= storage) {
                bin.push_back(game);
                fitted = true;
                break;
            }
        }

        if (!fitted) {
            bins.push_back({game});
        }
    }

    return bins;
}
```

Nous pouvons tester ces deux algorithmes sur plusieurs simulations, ce qui nous renvoie :

```{r, echo=FALSE, out.width="50%",}
games <- sample(1:50, 15, replace = TRUE)
storage <- 100

bins_R <- ffd_bin_packing(games, storage)
bins_Cpp <- ffd_bin_packing_Rcpp(games, storage)

cat("Jeux à stocker:", games, "\n")
cat("Capacité de stockage de chaque mémoire:", storage, "\n\n")

cat("Version R\n")
for (i in seq_along(bins_R)) {
  cat("Mémoire", i, ":", bins_R[[i]], "\n")
}

cat("\n\n")

cat("Version C++\n")
for (i in seq_along(bins_Cpp)) {
  cat("Mémoire", i, ":", bins_Cpp[[i]], "\n")
}
```

## Explication de l'algorithme

* Dans un premier temps, nous trions les jeux par ordre décroissant de taille. Ainsi, les jeux les plus grands seront placés en premier dans les bac, ce qui améliore l'efficacité de l'algorithme en réduisant le nombre de mémoires nécessaires.

* On initialise ensuite une liste vide qui sera utilisée pour stocker les différentes mémoires. Chaque élément de la liste représentera un espace mémoire, et la somme des jeux dans chaque mémoire ne dépassera pas la capacité de stockage totale de la mémoire.

* Par la suite, on itère sur chacun des jeux dans la liste triée. L'objectif est de trouver un espace mémoire où le jeu peut être placé. Pour cela, on itère une deuxième fois, cette fois-ci sur la liste des espaces mémoire : pour chaque mémoire, l'algorithme vérifie sur le jeu sélectionné peut être placé dans ce bac, sans dépasser la capacité de stockage. Pour cela, on vérifie si la somme des tailles des jeux déjà dans le bac courant additionné à la taille du jeu courant est inférieure ou égale à la capacité de stockage : si tel est le cas, le jeu courant peut être placé dans cet espace mémoire.

* Une fois que le jeu a été placé dans un espace mémoire, on met à jour la variable `fitted` en lui attribuant la valeur `TRUE` pour indiquer que le jeu courant a trouvé son espace mémoire. On sort de la boucle avec l'instruction `break`.

* Enfin, si le jeu courant n'a pas été placé dans un espace mémoire existant, créons un nouveau espace pour y placer le jeu courant.

## Analyse théorique de la complexité

Les algorithmes `R` et `C++` fonctionnent sensiblement de la même manière, l'analyse de leur complexité est donc équivalente.

* Dans un premier temps, le tri des jeux, avec `sort()` ou `std::sort()`, a une complexité temporelle de $\text{O}(n\log(n))$, dans le pire des cas, $n$ étant la taille du vecteur des jeux.

* L'initialisation de la liste des bacs est une opération constante, donc en $\text{O}(1)$.

* La boucle qui itère sur chaque jeu a une complexité de $\text{O}(n)$. Cependant, pour chaque jeu, nous avons une autre boucle qui itère sur les espaces mémoire. Dans le pire des cas, chaque jeu est placé dans une mémoire différente, donc il y a autant de mémoires que de jeux. Cela signifie que cette boucle a aussi une complexité de $\text{O}(n)$. Comme cette boucle est à l'intérieur de la boucle sur les jeux, la complexité totale de ces deux boucles imbriquées est $\text{O}(n^2)$.

* Les opérations à l'intérieur de la boucle sur les espaces mémoire sont toutes des opérations constantes, donc ayant une complexité en $\text{O}(1)$. Cependant, étant à l'intérieur de la boucle sur les espaces mémoire, elles ont une complexité totale en $\text{O}(n)$.

* Enfin, l'opération de création d'un nouvel espace mémoire dans le cas où cela est néccesaire est à l'intérieur de la boucle sur les jeux, elle a donc une complexité totale en $\text{O}(n)$.

**Ainsi, en combinant toutes ces complexités, on obtient une complexité totale pour l'algorithme en $\text{O}(n^2)$.**

## Vérification de la complexité sur des exemples

```{r, echo = FALSE, out.width="50%", fig.align="center"}
measure_execution_time_R <- function(sizes, storage) {
  execution_times <- numeric(length(sizes))
  for (i in seq_along(sizes)) {
    games <- runif(sizes[i], min = 1, max = 100)  
    execution_times[i] <- median(microbenchmark(ffd_bin_packing(games, storage), 
                                                times = 10)$time)
  }
  return(data.frame(Size = sizes, ExecutionTime = execution_times, Language = "R"))
}

measure_execution_time_cpp <- function(sizes, storage) {
  execution_times <- numeric(length(sizes))
  for (i in seq_along(sizes)) {
    games <- sample(1:100, sizes[i], replace = TRUE)  
    execution_times[i] <- median(microbenchmark(ffd_bin_packing_Rcpp(games, storage), 
                                                times = 10)$time)
  }
  return(data.frame(Size = sizes, ExecutionTime = execution_times, Language = "C++"))
}

sizes <- seq(10, 1000, by = 10)
storage <- 1000

execution_data_R <- measure_execution_time_R(sizes, storage)
execution_data_cpp <- measure_execution_time_cpp(sizes, storage)

plot_R <- ggplot(execution_data_R, aes(x = Size, y = ExecutionTime)) +
  geom_line() +
  geom_point() +
  labs(x = "Taille des données", y = "Temps d'exécution (en microsecondes)", 
       title = "Complexité (version R)") +
  theme_minimal()

plot_cpp <- ggplot(execution_data_cpp, aes(x = Size, y = ExecutionTime)) +
  geom_line() +
  geom_point() +
  labs(x = "Taille des données", y = "Temps d'exécution (en microsecondes)", 
       title = "Complexité (version C++)") +
  theme_minimal()

grid.arrange(plot_R, plot_cpp, ncol = 2)
```
On reconnaît aisément une fonction sensiblement proche de la fonction $n \mapsto n^2$. Nous pouvons voir, en comparant les temps d'exécution, que l'algorithme `C++` est plus rapide que la fonction `R`.

## Comparaison des temps d'exécution pour le _First-fit-decreasing bin packing_

```{r, echo=FALSE, out.width="50%", fig.align="center"}
source("StorageOptimisation/R/ffd_bin_packing.R")
sourceCpp("StorageOptimisation/src/ffdBinPacking.cpp")

sizes <- seq(10, 1000, by = 10)

execution_times_R <- measure_execution_time_R(sizes, storage = 10)
execution_times_Cpp <- measure_execution_time_cpp(sizes, storage = 10)

ggplot() +
  geom_point(data = execution_times_R, aes(x = log(Size), y = log(ExecutionTime), color = Language), shape = 1) +
  geom_point(data = execution_times_Cpp, aes(x = log(Size), y = log(ExecutionTime), color = Language), shape = 1) +
  labs(x = "log(n)", y = "log(T(n))", title = "Comparison of R vs C++ implementation") +
  scale_color_manual(values = c("blue", "red"), name = "Language") +
  theme_minimal()
```

Nous pouvons voir, comme attente, que la complexité temporelle des deux algorithmes évolue de la même manière, \emph{i.e.} de manière quadratique. Toutefois, l'algorithme `C++` est nettement plus rapide que sa version `R`, notamment pour les grandes valeurs de $n$.

# Algorithme naïf

# Algorithme optimisé